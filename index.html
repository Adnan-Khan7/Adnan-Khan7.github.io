<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Adnan Khan Portfolio</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
            color: #333;
        }
        header {
            background: #0056b3;
            color: #fff;
            padding: 20px 0;
            text-align: center;
        }
        header a {
            color: #ffdf00;
            text-decoration: none;
        }
        .container {
            width: 80%;
            margin: 0 auto;
            padding: 20px;
        }
        .section {
            background: white;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        h1, h2 {
            color: #333;
        }
        a {
            color: #0056b3;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        .subsection h3 {
            color: #0056b3;
        }
        footer {
            text-align: center;
            padding: 20px 0;
            background: #333;
            color: white;
        }
        @media (max-width: 768px) {
            .container {
                width: 90%;
            }
        }
    </style>
</head>
<body>
    <header>
        <h1>Adnan Khan</h1>
        <p><strong>AI and Machine Learning Researcher</strong></p>
        <p>Email: <a href="mailto:adnan.khan5@cmail.carleton.ca">adnankhan5@cmail.carleton.ca</a> | LinkedIn: <a href="https://www.linkedin.com/in/adnan-khan-aba952153/" target="_blank">Adnan Khan</a></p> 
        <p>GitHub: <a href="https://github.com/Adnan-Khan7">Adnan-Khan7</a> | Google Scholar: <a href="https://scholar.google.ca/citations?user=Ho7YNT4AAAAJ&hl=en" target="_blank">Adnan Khan</a></p> 
    </header>

    <div class="container">
        <section class="section">
            <h2>About Me</h2>
            <p>AI and Machine Learning researcher with a strong foundation in Computer Vision and Natural Language Processing. I enjoy working on interdisciplinary problems spanning accessibility, healthcare, and multimodal learning. I'm currently pursuing a PhD in Computer Science with a focus on applying Generative AI to accessibility and healthcare solutions, combining research depth with a practical, human-centered approach. I thrive on cross-cultural collaboration and enjoy tea as much as a well-trained model.</p>
        </section>

        <section class="section">
            <h2>Education</h2>
            <div class="subsection">
                <h3>PhD in Computer Science ðŸ‡¨ðŸ‡¦</h3>
                <p>Carleton University, Canada<br>
                Focus: Generative AI & Multimodal Learning<br>
                <em>2023 â€“ Present</em></p>
            </div>
            <div class="subsection">
                <h3>MSc in Computer Vision ðŸ‡¦ðŸ‡ª</h3>
                <p>Mohamed bin Zayed University of Artificial Intelligence (MBZUAI), UAE<br>
                CGPA: 3.84<br>
                Thesis: Semi-Supervised Domain Generalization for Visual Recognition<br>
                <em>2021 â€“ 2023</em></p>
            </div>
            <div class="subsection">
                <h3>BS in Computer Engineering ðŸ‡µðŸ‡°</h3>
                <p>COMSATS University Islamabad, Abbottabad Campus, Pakistan<br>
                CGPA: 3.30 <br> 
                Thesis: Accident Prevention Framework on Mountainous Roads Blind Spots <br>
                <em>2016 â€“ 2020</em></p>
            </div>
        </section>

        <section class="section">
            <h2>Publications</h2>

            <div class="subsection">
                <h3>TactileNet: Bridging the Accessibility Gap with AI-Generated Tactile Graphics for Individuals with Vision Impairment</h3>
                <p>Aceepted at <strong> IEEE SMC 2025</strong>, Vienna, Austria.<br>
                <em>Adnan Khan, Alireza Choubineh, Mai A. Shaaban, Abbas Akkasi, Majid Komeili</em></p>
                 <a href="https://arxiv.org/abs/2504.04722" target="_blank">Read Paper</a></p>
            </div>

            <div class="subsection">
                <h3>Text-Guided Image-to-Image Translation for Tactile Map Generation</h3>
                <p>Published at <strong>IJCNN 2025</strong>, Rome, Italy.<br>
                <em>Alireza Choubineh, Abbas Akkasi, Adnan Khan, Majid Komeili</em></p>
            </div>

            <div class="subsection">
                <h3>MedPromptX: Grounded Multimodal Prompting for Chest X-Ray Diagnosis</h3>
                <p>Published at <strong>MICCAI 2024</strong>, Marrakesh, Morocco.<br>
                <em>Mai A. Shaaban, Adnan Khan, Mohammad Yaqub</em></p>
                 <a href="https://link.springer.com/chapter/10.1007/978-3-031-84525-3_18" target="_blank">Read Paper</a></p>
            </div>

            <div class="subsection">
                <h3>Fine-Tuned Large Language Models for Symptom Recognition from Spanish Clinical Text</h3>
                <p>SympTEMIST Shared Task, part of <strong>AMIA 2024</strong>, New Orleans, USA.<br>
                <em>Mai A. Shaaban, Abbas Akkasi, Adnan Khan, Majid Komeili, Mohammad Yaqub</em></p>
                <a href="https://arxiv.org/abs/2401.15780" target="_blank">Read Paper</a></p>
            </div>

            <div class="subsection">
                <h3>Contrastive Self-Supervised Learning: A Survey on Different Architectures</h3>
                <p>Published at <strong>ICAI 2022</strong>. Islamabad, Pakistan.<br>
                <em>Adnan Khan, Sarah AlBarris, Arslan Manzoor</em></p>
                <a href="https://ieeexplore.ieee.org/document/9773725" target="_blank">Read Paper</a>
            </div>
        </section>

        <footer>
            <p>Â© 2025 Adnan Khan. All rights reserved.</p>
        </footer>
    </div>
</body>
</html>
